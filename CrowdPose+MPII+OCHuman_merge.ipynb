{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c19d088-4cc6-4b05-9a13-d6804ee6523c",
   "metadata": {},
   "source": [
    "# Dataset merge: CrowdPose + MPII + OCHuman for keypoints\n",
    "- Use MPII + OCHuman in COCO syntax (Datasets_to_COCO.ipynb)\n",
    "- Duplicate image paths exported with duplicate_image_finder.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4259b609-5ced-4829-9a43-047525916fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint as _pprint\n",
    "def pprint(data): (_pprint(data, sort_dicts=False))\n",
    "from configs import cfg\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import shutil\n",
    "import copy\n",
    "import numpy as np\n",
    "import fiftyone as fo\n",
    "import webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "653477ca-935c-4cec-ab3c-002133043651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images from all combined datasets\n",
    "# train images from main dataset to later test on + all images from other dataset\n",
    "img_dir = '/Users/john/datasets/crowdpose_mpii_ochuman/images'\n",
    "\n",
    "# ... same for annotation files\n",
    "anno_files = [\n",
    "    '/Users/john/datasets/crowdpose_mpii_oc/json/crowdpose_trainval_coco.json',  # crowd_pose train/val\n",
    "    '/Users/john/datasets/crowdpose_mpii_oc/json/ochuman_coco.json',  # all (= train + test)\n",
    "    '/Users/john/datasets/crowdpose_mpii_oc/json/mpii_coco.json',  # all \n",
    "    '/Users/john/datasets/crowdpose_mpii_oc/json/crowdpose_test.json',  # main test (crowd_pose) \n",
    "    '/Users/john/datasets/crowdpose_mpii_oc/json/overlap_export.json'  # image overlap log\n",
    "] \n",
    "\n",
    "with open(anno_files[0]) as f0, open(anno_files[1]) as f1, open(anno_files[2]) as f2, open(anno_files[3]) as f3, open(anno_files[4]) as f4:\n",
    "    crowd = json.load(f0)\n",
    "    oc = json.load(f1)\n",
    "    mpii = json.load(f2)\n",
    "    main_test = json.load(f3)\n",
    "    overlap = json.load(f4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7262d675-b5ee-4392-b5c8-1f9f2bf5a480",
   "metadata": {},
   "source": [
    "## 1. Reange keypoints to crowdpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb7b2d33-9511-4a4a-b234-f7af64fa91d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_oc = copy.deepcopy(oc)\n",
    "new_mpii = copy.deepcopy(mpii)\n",
    "\n",
    "for anno in new_oc['annotations']:\n",
    "    kps = anno['keypoints']\n",
    "    kps = np.array_split(kps, len(kps)/3)\n",
    "    # rearange, drop eyes, ears, nose\n",
    "    kps = [kps[3], kps[0], kps[4], kps[1], kps[5],\n",
    "           kps[2], kps[9], kps[6], kps[10],\n",
    "           kps[7], kps[11], kps[8], kps[12], kps[13]]\n",
    "    kps = list(np.array(kps).flatten())\n",
    "    kps = [round(val) for val in kps]\n",
    "    anno['keypoints'] = kps\n",
    "    anno['num_keypoints'] = len([vis for vis in kps[2::3] if vis > 0])\n",
    "\n",
    "for anno in new_mpii['annotations']:\n",
    "    kps = anno['keypoints']\n",
    "    kps = np.array_split(kps, len(kps)/3)\n",
    "    # rearange, drop pelvis and thorax\n",
    "    kps = [kps[13], kps[12], kps[14], kps[11], kps[15],\n",
    "           kps[10], kps[3], kps[2], kps[4],\n",
    "           kps[1], kps[5], kps[0], kps[9], kps[8]]\n",
    "    kps = list(np.array(kps).flatten())\n",
    "    kps = [round(val) for val in kps]\n",
    "    anno['keypoints'] = kps\n",
    "    anno['num_keypoints'] = len([vis for vis in kps[2::3] if vis > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b28dbb7-779c-4670-865e-94ed99de6967",
   "metadata": {},
   "source": [
    "## 2. Avoid duplicate ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53aa6525-3d19-46c6-ad56-ebc5a83d88bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_ids:crowd: 100000-119999\n",
      "img_ids:oc: 1-5081\n",
      "img_ids:mpii: 5-24985\n",
      "\n",
      "\n",
      "anno_ids:crowd: 100001-186784\n",
      "anno_ids:oc: 1-13360\n",
      "anno_ids:mpii: 1-28883\n",
      "\n",
      "\n",
      "img_ids:crowd: 100000-119999\n",
      "img_ids:oc: 200001-205081\n",
      "img_ids:mpii: 300005-324985\n",
      "\n",
      "\n",
      "anno_ids:crowd: 100001-186784\n",
      "anno_ids:oc: 200001-213360\n",
      "anno_ids:mpii: 300001-328883\n"
     ]
    }
   ],
   "source": [
    "ids_images = {\n",
    "    'crowd': [idx['id'] for idx in crowd['images'] + main_test['images']],\n",
    "    'oc': [idx['id'] for idx in oc['images']],\n",
    "    'mpii': [idx['id'] for idx in mpii['images']],\n",
    "}\n",
    "ids_annotations = {\n",
    "    'crowd': [idx['id'] for idx in crowd['annotations'] + main_test['annotations']],\n",
    "    'oc': [idx['id'] for idx in oc['annotations']],\n",
    "    'mpii': [idx['id'] for idx in mpii['annotations']],\n",
    "}\n",
    "for dataset, img_ids in ids_images.items():\n",
    "    print(f'img_ids:{dataset}: {min(img_ids)}-{max(img_ids)}')\n",
    "print('\\n')\n",
    "for dataset, img_ids in ids_annotations.items():\n",
    "    print(f'anno_ids:{dataset}: {min(img_ids)}-{max(img_ids)}')\n",
    "    \n",
    "BASE_OC = 200_000\n",
    "BASE_MPII = 300_000\n",
    "\n",
    "for anno in new_oc['annotations']:\n",
    "    anno['id'] += BASE_OC\n",
    "    anno['image_id'] += BASE_OC\n",
    "for img in new_oc['images']:\n",
    "    img['id'] += BASE_OC\n",
    "    \n",
    "for anno in new_mpii['annotations']:\n",
    "    anno['id'] += BASE_MPII\n",
    "    anno['image_id'] += BASE_MPII\n",
    "for img in new_mpii['images']:\n",
    "    img['id'] += BASE_MPII\n",
    "    \n",
    "# Test\n",
    "print('\\n')\n",
    "ids_images = {\n",
    "    'crowd': [idx['id'] for idx in crowd['images'] + main_test['images']],\n",
    "    'oc': [idx['id'] for idx in new_oc['images']],\n",
    "    'mpii': [idx['id'] for idx in new_mpii['images']],\n",
    "}\n",
    "ids_annotations = {\n",
    "    'crowd': [idx['id'] for idx in crowd['annotations'] + main_test['annotations']],\n",
    "    'oc': [idx['id'] for idx in new_oc['annotations']],\n",
    "    'mpii': [idx['id'] for idx in new_mpii['annotations']],\n",
    "}\n",
    "for dataset, img_ids in ids_images.items():\n",
    "    print(f'img_ids:{dataset}: {min(img_ids)}-{max(img_ids)}')\n",
    "print('\\n')\n",
    "for dataset, img_ids in ids_annotations.items():\n",
    "    print(f'anno_ids:{dataset}: {min(img_ids)}-{max(img_ids)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6db0473-9872-4309-a148-d9c66aecc72c",
   "metadata": {},
   "source": [
    "## 3. Remove image overlap \n",
    "Remove images from added datasets that are already in crowdpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7ef50fe-9455-4004-a6b3-6d1ebac361b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(oc_remove)=717\n",
      "len(oc[\"images\"])=5081\n",
      "len(oc[\"annotations\"])=10375\n",
      "len(new_oc['images'])=4364\n",
      "len(new_oc['annotations'])=8918\n"
     ]
    }
   ],
   "source": [
    "# ... the only overlap is between crowdpose and ochuman (704 images)\n",
    "# remove images + annotations from ochuman\n",
    "\n",
    "oc_remove = set()\n",
    "pairs = overlap['ochuman']['overlap']['image_pairs']\n",
    "for pair in pairs:\n",
    "    for (dataset, image) in pair:\n",
    "        if dataset == 'ochuman':\n",
    "            oc_remove.add(image)\n",
    "print(f'{len(oc_remove)=}')\n",
    "\n",
    "oc_remove_img_id = {image['id'] for image in new_oc['images'] if image['file_name'] in oc_remove}\n",
    "print(f'{len(oc[\"images\"])=}')\n",
    "print(f'{len(oc[\"annotations\"])=}')\n",
    "\n",
    "# For some reason, those loops have to run 3x to remove all 717 images\n",
    "# Are list ids newly assignes after pops?\n",
    "# removed_img = [new_oc['images'].pop(i) for i, image in enumerate(new_oc['images']) if image['id'] in oc_remove_img_id]\n",
    "# removed_anno = [new_oc['annotations'].pop(i) for i, annotation in enumerate(new_oc['annotations']) if annotation['image_id'] in oc_remove_img_id]\n",
    "\n",
    "# ... do the reverse instead\n",
    "img = [image for image in new_oc['images'] if image['id'] not in oc_remove_img_id]\n",
    "anno = [annotation for annotation in new_oc['annotations'] if annotation['image_id'] not in oc_remove_img_id]\n",
    "new_oc.pop('images')\n",
    "new_oc['images'] = img\n",
    "new_oc.pop('annotations')\n",
    "new_oc['annotations'] = anno\n",
    "\n",
    "print(f\"{len(new_oc['images'])=}\")\n",
    "print(f\"{len(new_oc['annotations'])=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d84fbb-682c-40ce-9aa0-59eb712096cd",
   "metadata": {},
   "source": [
    "## 4. Merge annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46de7f8e-0d05-4745-a7b4-2033ded5e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = {}\n",
    "merge['info'] = {\n",
    "        \"description\": \"CrowdPose/MPII/OCHuman merge\",\n",
    "        \"version\": \"1.0\",\n",
    "        \"year\": 2022,\n",
    "        \"date_created\": \"2022/10/11\",\n",
    "        \"merged_by\": \"John Hoffmann\",\n",
    "        \"merge_note\": \"14 keypoints (CrowdPose). CrowdPose trainval/MPII train/OCHUMAN valtest. COCO syntax. Approx. bbox around keypoints and bbox as segmentation, if no bbox/segmentation was given.\",\n",
    "        \"license_mpii\":  \"\"\"Simplified BSD License. Copyright (c) 2015, Max Planck Institute for Informatics. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\"\"\",\n",
    "        \"license_ochuman\": \"\"\"MIT License. Copyright (c) 2018 Roy Tseng. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\"\"\",\n",
    "    }\n",
    "merge['categories'] = crowd['categories']\n",
    "for image in crowd['images']:\n",
    "    image['dataset'] = 'CrowdPose'\n",
    "for image in new_oc['images']:\n",
    "    image['dataset'] = 'OCHuman'\n",
    "for image in new_mpii['images']:\n",
    "    image['dataset'] = 'MPII'\n",
    "merge['images'] = crowd['images'] + new_oc['images'] + new_mpii['images']\n",
    "merge['annotations'] = crowd['annotations'] + new_oc['annotations'] + new_mpii['annotations']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb479069-f9b6-46af-af72-ccc90374889a",
   "metadata": {},
   "source": [
    "## 5. Add CrowdPose's crowdIndex\n",
    "Contains some outliers in CrowdPose due to wrong annotations in CrowdPose + some errors according to the equation stated in the paper. However, for CrowdPose annotations, the orinial crowdIndex is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98e1cff1-0acd-4f20-b9c4-5f7f4dfdd582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52444efe2b12489f910c9e95d314a467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21772 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def point_in_rect(point, rect):\n",
    "    \"\"\"Check if point is in rectangle.\"\"\"\n",
    "    x1, y1, w, h = rect\n",
    "    x2, y2 = x1+w, y1+h\n",
    "    x, y = point\n",
    "    # Count on edge\n",
    "    if (x1 <= x and x <= x2):\n",
    "        if (y1 <= y and y <= y2):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "anno_lookup = {}\n",
    "crowdpose_image_ids = [image['id'] for image in merge['images'] if image['dataset'] == 'CrowdPose']\n",
    "for anno in merge['annotations']:\n",
    "    if anno['image_id'] not in crowdpose_image_ids and not anno['iscrowd']:  \n",
    "        # keep original crowdindex in crowdpose\n",
    "        # skip iscrowd instances (contains several people at once)\n",
    "        if anno['image_id'] not in anno_lookup:\n",
    "            anno_lookup[anno['image_id']] = []\n",
    "        anno_lookup[anno['image_id']].append(anno)\n",
    "\n",
    "crowdedness_all = {}\n",
    "pbar = tqdm(anno_lookup.items())\n",
    "for image_id, annos in pbar:\n",
    "    anno_ids = [anno['id'] for anno in annos]\n",
    "    bboxes = {}\n",
    "    keypoints = {}\n",
    "    crowdedness = {}\n",
    "    for anno in annos:\n",
    "        bboxes[anno['id']] = anno['bbox']\n",
    "        kps = anno['keypoints']\n",
    "        kps = np.array_split(kps, len(kps)/3)\n",
    "        kps = [list(kp) for kp in kps if kp[2] > 0]  # visible + hidden\n",
    "        keypoints[anno['id']] = kps\n",
    "    for idx in anno_ids:\n",
    "        bbox = bboxes[idx]\n",
    "        kp_count = {'kps_self': 0, 'kps_other': 0}\n",
    "        for anno_id, kps in keypoints.items():\n",
    "            if idx == anno_id:  # keypoints are in bbox of instance itself\n",
    "                for kp in kps:\n",
    "                    if point_in_rect((kp[0], kp[1]), bbox):\n",
    "                        kp_count['kps_self'] += 1\n",
    "            else:\n",
    "                for kp in kps:\n",
    "                    if point_in_rect((kp[0], kp[1]), bbox):\n",
    "                        kp_count['kps_other'] += 1\n",
    "        crowdedness[idx] = kp_count\n",
    "    crowdedness_all[image_id] = crowdedness\n",
    "    \n",
    "# calculate crowdIndex\n",
    "crowdIndex = {}\n",
    "for image_id, kps_stats in crowdedness_all.items():\n",
    "    ci_sum = 0\n",
    "    num_valid = 0\n",
    "    for stats in kps_stats.values():\n",
    "        try:\n",
    "            ci_sum += stats['kps_other']/stats['kps_self']\n",
    "            num_valid += 1\n",
    "        except ZeroDivisionError:\n",
    "            # people with 0 keypoints\n",
    "            pass\n",
    "    crowdIndex[image_id] = 0 if num_valid == 0 else ci_sum/num_valid\n",
    "\n",
    "for image in merge['images']:\n",
    "    if image['dataset'] != 'CrowdPose':\n",
    "        image['crowdIndex'] = round(crowdIndex[image['id']], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec45fcd-aa4b-4bda-96c2-eb0ba82d2df3",
   "metadata": {},
   "source": [
    "## Write output and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64d2e123-c0f3-4fe8-993d-7d83c0f4408a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write output\n",
    "export = Path(Path(anno_files[0]).parent, 'merge.json')\n",
    "with open(export, 'w', encoding='utf-8') as f:\n",
    "    json.dump(merge, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67da1a08-9d0f-4d8c-b134-89481a84139c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to FiftyOne on port 5151 at localhost.\n",
      "If you are not connecting to a remote session, you may need to start a new session and specify a port\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "# Check dataset in fiftyone\n",
    "port = 5151\n",
    "session = fo.launch_app(port=port)\n",
    "webbrowser.open(f'http://localhost:{port}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3fd57b9-84e7-4769-b865-696e90b1bb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 2000/2000 [47.8s elapsed, 0s remaining, 50.3 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_type = fo.types.COCODetectionDataset,\n",
    "    label_types = [\"detections\", \"segmentations\", \"keypoints\"],\n",
    "    data_path = f'/Users/john/datasets/crowdpose_mpii_oc/images',\n",
    "    labels_path = export,\n",
    "    max_samples=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e505284c-57b7-4e9a-842d-d0fc9f946479",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# session.view = dataset.view()  # show chosen\n",
    "session.view = dataset.take(1000).view()  # sample random 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f9b7d1-83b1-464a-bd89-23712248f60b",
   "metadata": {},
   "source": [
    "### Get subset from each dataset and check keypoint rearrangement in coco-annotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e5d1791-c913-4a23-8bd9-cbad99134e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = '/Users/john/datasets/crowdpose_mpii_oc/images'\n",
    "with open(export) as f:\n",
    "    old = json.load(f)\n",
    "    new = old.copy()\n",
    "    new.pop('images')\n",
    "    new.pop('annotations')\n",
    "    new['images'] = []\n",
    "    new['annotations'] = []\n",
    "    \n",
    "    image_ids = []\n",
    "    for dataset in ['CrowdPose', 'OCHuman', 'MPII']:\n",
    "        i = 0\n",
    "        for image in old['images']:\n",
    "            if image['dataset'] == dataset and i < 5:\n",
    "                new['images'].append(image)\n",
    "                image_ids.append(image['id'])\n",
    "                i += 1\n",
    "    for anno in old['annotations']:\n",
    "        if anno['image_id'] in image_ids:\n",
    "            new['annotations'].append(anno)\n",
    "    \n",
    "    export_img = Path(export.parent) / Path('img_export')\n",
    "    os.makedirs(export_img, exist_ok=True)\n",
    "    for img in new['images']:\n",
    "        destination = Path(export_img, img['file_name'])\n",
    "        shutil.copy((Path(img_dir) / img['file_name']), destination)\n",
    "\n",
    "\n",
    "with open(Path(export.parent, 'export.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(new, f, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
