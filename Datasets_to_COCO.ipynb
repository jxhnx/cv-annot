{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d2d652d-3b50-49ca-ae54-58d0cbf74fee",
   "metadata": {},
   "source": [
    "# MPII, OCHuman, CrowdPose to COCO syntax\n",
    "Transformation scripts for human keypoint datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5639d0d4-bdd6-466e-91d8-11d134e970fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint as _pprint\n",
    "def pprint(data): (_pprint(data, sort_dicts=False))\n",
    "from configs import cfg\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import fiftyone as fo\n",
    "import webbrowser\n",
    "from tqdm.notebook import tqdm\n",
    "from img_utils import show_images\n",
    "import shutil\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Convert OCHuman segmentation\n",
    "import ochumanApi.mask as mask_util\n",
    "from ochumanApi.ochuman import annToMask, Poly2Mask\n",
    "from fiftyone.utils.coco import _mask_to_polygons, _close_contour\n",
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bceb76-c150-4cec-9b62-1b1d7e4ac576",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MPII to COCO syntax\n",
    "All keypoint annotations in JSON format. MPII metadata. COCO syntax. Approx. bbox around keypoints + bbox as segmentation & area. Keypoint visibility changed to all annotated keypoints are visible (due to MPII counting self-occlusion as invisible, which contradicts to COCO logic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cffdf669-de45-4d76-b343-0ee7a3f2a5c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pesky_mpii_mat_to_json(anno_mat, img_dir):\n",
    "    \"\"\"\n",
    "    Transforms the pesky matlab .mat MPII annotation file to json.\n",
    "    MPII to COCO -> take all annotations with keypoints, keep extra MPII metadata, use COCO format for data representation.\n",
    "    \n",
    "    + adds bbox (approximate, generated around keypoints with MPII scale and objpos) and segmentation (bbox as segmentation) \n",
    "    in order to work with the standard COCO dataloader expecting those keys\n",
    "    \"\"\"\n",
    "    \n",
    "    mat = loadmat(anno_mat, simplify_cells=True)\n",
    "    annotations = mat['RELEASE']['annolist']  # len 24987\n",
    "    img_train = mat['RELEASE']['img_train']  # len 24987\n",
    "    activities = mat['RELEASE']['act']  # len 24987\n",
    "    videos = mat['RELEASE']['video_list']  # len 2821\n",
    "    single_person = mat['RELEASE']['single_person']  # len 24987\n",
    "    \n",
    "    output = {}\n",
    "    output['info'] = {}\n",
    "    output['categories'] = {}\n",
    "    output['activities'] = []\n",
    "    output['images'] = []\n",
    "    output['annotations'] = []\n",
    "   \n",
    "    output['info'] = {\n",
    "        \"description\": \"MPII Human Pose\",\n",
    "        \"url\": \"http://human-pose.mpi-inf.mpg.de/\",\n",
    "        \"version\": \"1.12\",\n",
    "        \"year\": 2014,\n",
    "        \"contributor\": \"Max Planck Institute for Informatics\",\n",
    "        \"date_created\": \"2014/09/23\",\n",
    "        \"modified_by\": \"John Hoffmann\",\n",
    "        \"modified_note\": \"All keypoint annotations in JSON format. MPII metadata. COCO syntax. Approx. bbox around keypoints + bbox as segmentation & area.\",\n",
    "        \"date_modified\": \"2022/10/11\",\n",
    "        \"license\":  \"\"\"Simplified BSD License. Copyright (c) 2015, Max Planck Institute for Informatics. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\"\"\"\n",
    "    }\n",
    "    \n",
    "    output['categories'] = [{\n",
    "            \"supercategory\": \"person\",\n",
    "            \"id\": 1,\n",
    "            \"name\": \"person\",\n",
    "            \"keypoints\": [\n",
    "                \"right_ankle\",\n",
    "                \"right_knee\",\n",
    "                \"right_hip\",\n",
    "                \"left_hip\",\n",
    "                \"left_knee\",\n",
    "                \"left_ankle\",\n",
    "                \"pelvis\",\n",
    "                \"thorax\",\n",
    "                \"upper_neck\",\n",
    "                \"head_top\",\n",
    "                \"right_wrist\",\n",
    "                \"right_elbow\",\n",
    "                \"right_shoulder\",\n",
    "                \"left_shoulder\",\n",
    "                \"left_elbow\",\n",
    "                \"left_wrist\"\n",
    "            ],\n",
    "            \"skeleton\": [\n",
    "                [1,2],\n",
    "                [2,3],\n",
    "                [3,7],\n",
    "                [4,5],\n",
    "                [4,7],\n",
    "                [5,6],\n",
    "                [7,8],\n",
    "                [8,14],\n",
    "                [8,13],\n",
    "                [9,10],\n",
    "                [11,12],\n",
    "                [12,13],\n",
    "                [14,15],\n",
    "                [15,16]\n",
    "            ]\n",
    "        }]\n",
    "\n",
    "    # get all annotations with keypoints\n",
    "    valid_annos = []\n",
    "    imgidx = 1\n",
    "    for entry in annotations:\n",
    "        if type(entry['annorect']) is dict:\n",
    "            entry['annorect'] = [entry['annorect']]  # apply same format to all annotations\n",
    "        if type(entry['annorect']) is list:\n",
    "            temp_entry = entry.copy()\n",
    "            temp_entry.pop('annorect')\n",
    "            temp_entry['annorect'] = []\n",
    "            temp_entry['imgidx'] = imgidx  # add index (position in matlab dataframe)\n",
    "            for annorect in entry['annorect']:\n",
    "                if 'annopoints' in annorect:\n",
    "                    if len(annorect['annopoints']) > 0:  # drop empty arrays\n",
    "                        if type(annorect['annopoints']['point']) == dict:  # contains only single point\n",
    "                            annorect['annopoints']['point'] = [annorect['annopoints']['point']]\n",
    "                        temp_entry['annorect'].append(annorect)\n",
    "            if len(temp_entry['annorect']) > 0:  # not empty annotations\n",
    "                valid_annos.append(temp_entry)\n",
    "        imgidx += 1\n",
    "\n",
    "    # get activities\n",
    "    valid_acts = {}\n",
    "    imgidx = 1\n",
    "    for entry in activities:\n",
    "        if entry['act_id'] != -1:\n",
    "            valid_acts[imgidx] = entry\n",
    "        imgidx +=1\n",
    "\n",
    "    # add activities\n",
    "    acts = {v['act_id']:v for v in valid_acts.values()}\n",
    "    acts[-1] = {'act_id': -1, 'cat_name': None, 'act_name': None}\n",
    "    acts = {key:acts[key] for key in sorted(acts.keys())}\n",
    "    output['activities'] = [{'act_id': act['act_id'], 'cat_name': act['cat_name'], 'act_name': act['act_name']} for act in acts.values()]\n",
    "\n",
    "    # get videos\n",
    "    valid_vids = {}\n",
    "    vididx = 1\n",
    "    for entry in videos:\n",
    "        valid_vids[vididx] = entry\n",
    "        vididx +=1\n",
    "\n",
    "    # get trainin/test assignment\n",
    "    valid_train = {}\n",
    "    imgidx = 1\n",
    "    for entry in img_train:\n",
    "        valid_train[imgidx] = int(entry)\n",
    "        imgidx +=1\n",
    "\n",
    "    # get singel person retangle ids\n",
    "    valid_single = {}\n",
    "    imgidx = 1\n",
    "    for entry in single_person:\n",
    "        valid_single[imgidx] = [entry] if type(entry) == int else list(entry)\n",
    "        valid_single[imgidx] = [int(e) for e in valid_single[imgidx]]\n",
    "        imgidx +=1\n",
    "\n",
    "    # add images/annotations in COCO format\n",
    "    anno_id = 1\n",
    "    for anno in valid_annos:\n",
    "        file_name = anno['image']['name']\n",
    "        img = Image.open(Path(img_dir, file_name)) \n",
    "        width, height = img.size\n",
    "        if type(anno['frame_sec']) == int:\n",
    "            frame_sec = anno['frame_sec']\n",
    "            frame_str = f'&t={frame_sec}'\n",
    "        else:\n",
    "            frame_sec = -1\n",
    "            frame_str = ''\n",
    "        if type(anno['vididx']) == int:\n",
    "            vid_link = f\"https://www.youtube.com/watch?v={valid_vids[anno['vididx']]}{frame_str}\"\n",
    "        else:\n",
    "            vid_link = -1\n",
    "        output['images'].append({\n",
    "            'file_name': file_name,\n",
    "            'id': anno['imgidx'],\n",
    "            'width': width,\n",
    "            'height': height,\n",
    "            'img_train': valid_train[anno['imgidx']],\n",
    "            'video_url': vid_link,\n",
    "            'frame_sec': anno['frame_sec'] if type(anno['frame_sec']) == int else -1,\n",
    "            'activitiy_id': -1 if anno['imgidx'] not in valid_acts else valid_acts[anno['imgidx']]['act_id'],\n",
    "            'single_person': valid_single[anno['imgidx']],\n",
    "            'annotations': len(anno['annorect'])\n",
    "        })\n",
    "\n",
    "        anno_per_img = 1\n",
    "        for annorect in anno['annorect']:\n",
    "            # head bbox\n",
    "            x1, y1, x2, y2 = annorect['x1'], annorect['y1'], annorect['x2'], annorect['y2']\n",
    "\n",
    "            # keypoints\n",
    "            points = annorect['annopoints']['point']\n",
    "            kps = [[0] * 3 for i in range(16)]  # create empty keypoints\n",
    "            for point in points:\n",
    "                # MPII counts self-occlusion as invisible, other datasets don't\n",
    "                # MPII does not differentiate between self-occlusion and occlusion through, e.g., objects\n",
    "                # Therefore, all annotated keypoints are handeled as visible\n",
    "                vis = 2  # COCO: visible and labeled\n",
    "                kps[point['id']] = [point['x'], point['y'], 2]\n",
    "            kps = [int(kp) for kp in list(np.array(kps).flatten())]  # flatten, use integers\n",
    "\n",
    "            ### approximate bbox\n",
    "            ## After Newell et al.\n",
    "            objpos = [annorect['objpos']['x'], annorect['objpos']['y']]  # x, y\n",
    "            scale = 200 * annorect['scale']\n",
    "            # upper_left = (objpos[0] - scale / 2, objpos[1] - scale / 2)\n",
    "            # bottom_right = (objpos[0] + scale / 2, objpos[1] + scale / 2)\n",
    "            # bbox = [upper_left[0], upper_left[1], bottom_right[0]-upper_left[0], bottom_right[1]-upper_left[1]]\n",
    "            \n",
    "            ## Without overflow, include all keypoints, fit better\n",
    "            # delete not annotated keypoints (v=0)\n",
    "            kps_temp = np.array_split(kps, len(kps)/3)\n",
    "            kps_temp = list(np.array([kp for kp in kps_temp if kp[2] > 0]).flatten())\n",
    "            kps_temp = [int(kp) for kp in kps_temp]\n",
    "            # define bounding box\n",
    "            xs = kps_temp[0::3]\n",
    "            ys = kps_temp[1::3]\n",
    "            bbox = [min(xs), min(ys), max(xs)-min(xs), max(ys)-min(ys)]\n",
    "            # give some margins\n",
    "            margin = annorect['scale'] * 10. # px, all directions\n",
    "            bbox = [bbox[0]-margin, bbox[1]-margin, bbox[2]+2*margin, bbox[3]+2*margin]\n",
    "            bbox = [int(i) for i in bbox]\n",
    "            # set to image edge if out of bounce\n",
    "            bbox[0] = bbox[0] if bbox[0] > 0 else 0\n",
    "            bbox[1] = bbox[1] if bbox[1] > 0 else 0\n",
    "            bbox[2] = bbox[2] if bbox[0]+bbox[2] < width else width-bbox[0]\n",
    "            bbox[3] = bbox[3] if bbox[1]+bbox[3] < height else height-bbox[1]\n",
    "            \n",
    "            # approximate bbox as segmentation\n",
    "            segmentation = [bbox[0]+bbox[2], bbox[1], bbox[0]+bbox[2], bbox[1]+bbox[3], bbox[0], bbox[1]+bbox[3], bbox[0], bbox[1]]\n",
    "            segmentation = [float(val) for val in segmentation]\n",
    "\n",
    "            output['annotations'].append({\n",
    "                'id': anno_id, # unique id for annotation\n",
    "                'image_id': anno['imgidx'],\n",
    "                'category_id': 1,  # person\n",
    "                'iscrowd': False,  # COCO meta for crowds, always false for this dataset\n",
    "                'keypoints': kps,\n",
    "                'num_keypoints': len(points), # annotated points\n",
    "                'bbox':  bbox,  # approximate around keypoints\n",
    "                'segmentation': [segmentation],  # bounding box as segmentation\n",
    "                'area': bbox[2] * bbox[3],\n",
    "                'isbbox': True,  # segmentation = bbox\n",
    "                'bbox_head': [x1, y1, x2-x1, y2-y1],  # x, y, width, height\n",
    "                'scale': annorect['scale'],\n",
    "                'objpos': objpos,\n",
    "                'single_person': 1 if anno_per_img in valid_single[anno['imgidx']] else 0 # 1 if sufficiently separated individual\n",
    "            })\n",
    "            anno_per_img += 1\n",
    "            anno_id += 1\n",
    "        \n",
    "    output['info']['annotated_images'] = len(output['images'])\n",
    "    output['info']['keypoint_annotations'] = len(output['annotations'])\n",
    "    \n",
    "    return output\n",
    "\n",
    "mpii_json = pesky_mpii_mat_to_json('/Users/john/datasets/mpii/mpii_human_pose_v1_u12_2/mpii_human_pose_v1_u12_1.mat', '/Users/john/datasets/mpii/images')\n",
    "\n",
    "with open(Path('/Users/john/datasets/mpii/mpii_human_pose_v1_u12_2', 'mpii_coco.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(mpii_json, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2647713-16b7-469b-94af-01fa6bae2c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "140c92b5-8505-4714-a978-89128b19e345",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## OCHuman to COCO syntax\n",
    "All keypoint annotations in JSON format. OCHuman metadata. COCO syntax. Bbox as segmentation & area. Keypoint visibility logic changed to COCO logic (self-occlusion = visible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4265de22-f63f-4a29-a690-91aa6571fc9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7059eeeff894c3f9b372586f15ac2b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5081 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def ochuman_to_coco_format(anno):\n",
    "    \"\"\"OCHuman annotations to COCO syntax. Bbox as segmentation & area.\"\n",
    "    \"\"\"\n",
    "    with open(anno) as f:\n",
    "        old = json.load(f)\n",
    "\n",
    "    output = {}\n",
    "    output['info'] = {}\n",
    "    output['categories'] = {}\n",
    "    output['images'] = []\n",
    "    output['annotations'] = []\n",
    "   \n",
    "    output['info'] = {\n",
    "        \"description\": \"OCHuman\",\n",
    "        \"url\": \"https://github.com/liruilong940607/OCHumanApi\",\n",
    "        \"version\": \"1.0\",\n",
    "        \"year\": 2019,\n",
    "        \"contributor\": \"OCHuman Team\",\n",
    "        \"date_created\": \"2019/06/13\",\n",
    "        \"modified_by\": \"John Hoffmann\",\n",
    "        \"modified_note\": \"All keypoint annotations in JSON format. OCHuman metadata. COCO syntax. Bbox as segmentation & area.\",\n",
    "        \"date_modified\": \"2022/09/17\",\n",
    "        \"license\":  \"\"\"MIT License. Copyright (c) 2018 Roy Tseng. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\"\"\"\n",
    "    }\n",
    "    \n",
    "    output['categories'] = [{\n",
    "            \"supercategory\": \"person\",\n",
    "            \"id\": 1,\n",
    "            \"name\": \"person\",\n",
    "            \"keypoints\": [\n",
    "                \"right_shoulder\",\n",
    "                \"right_elbow\",\n",
    "                \"right_wrist\",\n",
    "                \"left_shoulder\",\n",
    "                \"left_elbow\",\n",
    "                \"left_wrist\",\n",
    "                \"right_hip\",\n",
    "                \"right_knee\",\n",
    "                \"right_ankle\",\n",
    "                \"left_hip\",\n",
    "                \"left_knee\",\n",
    "                \"left_ankle\",\n",
    "                \"head\",\n",
    "                \"neck\",\n",
    "                \"right_ear\",\n",
    "                \"left_ear\",\n",
    "                \"nose\",\n",
    "                \"right_eye\",\n",
    "                \"left_eye\"\n",
    "            ],\n",
    "            \"skeleton\": [\n",
    "                [1,15],\n",
    "                [1,4],\n",
    "                [1,2],\n",
    "                [1,7],\n",
    "                [2,3],\n",
    "                [4,16],\n",
    "                [4,5],\n",
    "                [4,10],\n",
    "                [5,6],\n",
    "                [7,10],\n",
    "                [7,8],\n",
    "                [8,9],\n",
    "                [10,11],\n",
    "                [11,12],\n",
    "                [13,14],\n",
    "                [15,18],\n",
    "                [16,19],\n",
    "                [17,19],\n",
    "                [17,18]\n",
    "            ]\n",
    "        }]\n",
    "    \n",
    "    anno_id = 0\n",
    "    pbar = tqdm(old['images'])\n",
    "    for img in pbar:\n",
    "        output['images'].append({\n",
    "            'file_name' :img['file_name'],\n",
    "            'id': int(img['image_id']),\n",
    "            'width': img['width'],\n",
    "            'height': img['height']\n",
    "            \n",
    "        })\n",
    "        for anno in img['annotations']:\n",
    "            anno_id += 1\n",
    "            if anno['keypoints'] != None:\n",
    "                # adjust keypoints\n",
    "                kps = anno['keypoints']\n",
    "                kps = [int(kp) for kp in kps]\n",
    "                assert len(kps) == 19 * 3\n",
    "                num_keypoints = len([vis for vis in kps[2::3] if vis > 0])  # count only annotated\n",
    "                # To COCO vis definition\n",
    "                for i, vis in enumerate(kps):\n",
    "                    if i % 3:\n",
    "                        if vis == 1 or vis == 2:\n",
    "                            kps[i] = 2\n",
    "                        elif vis == 3:\n",
    "                            kps[i] = 1\n",
    "                \n",
    "                # adjust bbox xyxy -> xywh to COCO format\n",
    "                x1, y1, x2, y2 = anno['bbox']\n",
    "                bbox = [x1, y1, x2-x1, y2-y1]\n",
    "                area = (x2-x1)*(y2-y1)\n",
    "\n",
    "                # Add segmentation with help of APIs\n",
    "                if anno['segms'] != None:\n",
    "                    # Segmentation\n",
    "                    mask = Poly2Mask(anno['segms'])\n",
    "                    # or compressed\n",
    "                    # maskencode = mask_util.encode(np.asfortranarray(mask))\n",
    "                    # maskencode['counts'] = maskencode['counts'].decode('ascii')\n",
    "                    # segmentation = maskencode\n",
    "                    mask = _mask_to_polygons(mask, 1)\n",
    "                    segmentation = mask\n",
    "                    isbbox = False\n",
    "                else:\n",
    "                # Add bounding box as segmentation for the remaining\n",
    "                    segmentation = [bbox[0]+bbox[2], bbox[1], bbox[0]+bbox[2], bbox[1]+bbox[3], bbox[0], bbox[1]+bbox[3], bbox[0], bbox[1]]\n",
    "                    segmentation = [ [float(val) for val in segmentation] ]\n",
    "                    isbbox = True\n",
    "\n",
    "                # add annotation if it contains keypoints\n",
    "                output['annotations'].append({\n",
    "                    'id': anno_id,\n",
    "                    'image_id': int(img['image_id']),\n",
    "                    'category_id': 1,  # person\n",
    "                    'iscrowd': False,  # no crowd annotations in ochuman\n",
    "                    'keypoints': kps,\n",
    "                    'num_keypoints': num_keypoints,\n",
    "                    'bbox': bbox,\n",
    "                    'segmentation': segmentation,\n",
    "                    'area': area,\n",
    "                    'isbbox': isbbox,\n",
    "                    'max_iou': anno['max_iou'],\n",
    "                })\n",
    "                \n",
    "    output['info']['annotated_images'] = len(output['images'])\n",
    "    output['info']['keypoint_annotations'] = len(output['annotations'])\n",
    "    \n",
    "    return output\n",
    "    \n",
    "\n",
    "ochuman_json = ochuman_to_coco_format('/Users/john/datasets/ochuman/ochuman.json')\n",
    "\n",
    "with open(Path('/Users/john/datasets/ochuman/', 'ochuman_coco.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(ochuman_json, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a616db6a-0d40-4e0c-8be1-ca56e0275491",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## CrowdPose to COCO syntax\n",
    "All keypoint annotations in JSON format. CrowdPose metadata. COCO syntax. Bbox as segmentation & area. Keypoint visibility in COCO logic, all head + neck points changed to visible (annotated as not visible in CrowdPose for some reason)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f3c37ce-791a-4e48-8a6e-13aff459da2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crowdpose_to_coco_format(anno):\n",
    "    \"\"\"CrowdPose annotations to COCO syntax. Bbox as segmentation & area.\"\n",
    "    \"\"\"\n",
    "    with open(anno) as f:\n",
    "        old = json.load(f)\n",
    "\n",
    "    output = {}\n",
    "    output['info'] = {}\n",
    "    output['categories'] = {}\n",
    "    output['images'] = []\n",
    "    output['annotations'] = []\n",
    "   \n",
    "    output['info'] = {\n",
    "        \"description\": \"CrowdPose\",\n",
    "        \"url\": \"https://github.com/Jeff-sjtu/CrowdPose\",\n",
    "        \"version\": \"1.0\",\n",
    "        \"year\": 2020,\n",
    "        \"contributor\": \"CrowdPose & MMPose team\",\n",
    "        \"date_created\": \"2020/12/26\",\n",
    "        \"modified_by\": \"John Hoffmann\",\n",
    "        \"modified_note\": \"All keypoint annotations in JSON format. CrowdPose metadata. COCO syntax. Drop iscrowd=1 (wrongly annotated). Bbox as segmentation & area.\",\n",
    "        \"date_modified\": \"2022/09/17\"\n",
    "    }\n",
    "    \n",
    "    output['categories'] = [{\n",
    "            \"supercategory\": \"person\",\n",
    "            \"id\": 1,\n",
    "            \"name\": \"person\",\n",
    "            \"keypoints\": [\n",
    "                \"left_shoulder\",\n",
    "                \"right_shoulder\",\n",
    "                \"left_elbow\",\n",
    "                \"right_elbow\",\n",
    "                \"left_wrist\",\n",
    "                \"right_wrist\",\n",
    "                \"left_hip\",\n",
    "                \"right_hip\",\n",
    "                \"left_knee\",\n",
    "                \"right_knee\",\n",
    "                \"left_ankle\",\n",
    "                \"right_ankle\",\n",
    "                \"head\",\n",
    "                \"neck\"\n",
    "            ],\n",
    "            \"skeleton\": [\n",
    "                [1,14],\n",
    "                [1,3],\n",
    "                [2,14],\n",
    "                [2,4],\n",
    "                [3,5],\n",
    "                [4,6],\n",
    "                [7,14],\n",
    "                [7,9],\n",
    "                [8,14],\n",
    "                [8,10],\n",
    "                [9,11],\n",
    "                [10,12],\n",
    "                [13,14]\n",
    "            ]\n",
    "        }]\n",
    "    \n",
    "    for img in old['images']:\n",
    "        output['images'].append({\n",
    "            'file_name': img['file_name'],\n",
    "            'id': img['id'],\n",
    "            'width': img['width'],\n",
    "            'height': img['height'],\n",
    "            'crowdIndex': img['crowdIndex'],\n",
    "        })\n",
    "        \n",
    "    for anno in old['annotations']:\n",
    "        # keypoints\n",
    "        kps = anno['keypoints']\n",
    "        kps[13*3-1] = 2 if kps[13*3-1] > 0 else kps[13*3-1] # head to visible\n",
    "        kps[14*3-1] = 2 if kps[14*3-1] > 0 else kps[14*3-1] # neck to visible\n",
    "        num_keypoints = len([vis for vis in kps[2::3] if vis > 0])\n",
    "        \n",
    "        # bbox as segmentation\n",
    "        bbox = anno['bbox']\n",
    "        segmentation = [bbox[0]+bbox[2], bbox[1], bbox[0]+bbox[2], bbox[1]+bbox[3], bbox[0], bbox[1]+bbox[3], bbox[0], bbox[1]]\n",
    "        segmentation = [ [round(val, 2) for val in segmentation] ]\n",
    "        isbbox = True\n",
    "        area = bbox[2]*bbox[3]\n",
    "        \n",
    "        # only if keypoints and not a crowd (iscrowd = True: more than one person, typically wrongly annotated)\n",
    "        if num_keypoints > 0 and not anno['iscrowd']:\n",
    "            output['annotations'].append({\n",
    "                'id': anno['id'],\n",
    "                'image_id': anno['image_id'],\n",
    "                'category_id': anno['category_id'],\n",
    "                'iscrowd': anno['iscrowd'],\n",
    "                'keypoints': kps,\n",
    "                'num_keypoints': num_keypoints,\n",
    "                'bbox': anno['bbox'],\n",
    "                'segmentation': segmentation,\n",
    "                'area': area,\n",
    "                'isbbox': isbbox,\n",
    "            })\n",
    "                \n",
    "    output['info']['annotated_images'] = len(output['images'])\n",
    "    output['info']['keypoint_annotations'] = len(output['annotations'])\n",
    "    \n",
    "    return output\n",
    "    \n",
    "\n",
    "crowdpose_json = crowdpose_to_coco_format('/Users/john/datasets/crowd_pose/json/crowdpose_test.json')\n",
    "\n",
    "with open(Path('/Users/john/datasets/crowd_pose/json/', 'crowdpose_test_coco.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(crowdpose_json, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1feb86-a4a5-4b77-9089-2f735dc0082b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Check dataset in fiftyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ade60f9-7aba-43d9-b583-6506927b31f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# check in fiftyone\n",
    "# start\n",
    "port = 5151\n",
    "session = fo.launch_app(port=port)\n",
    "webbrowser.open(f'http://localhost:{port}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d69637e-aca4-4061-b6d9-ab1d44f8909e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 2000/2000 [28.1s elapsed, 0s remaining, 60.6 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_type = fo.types.COCODetectionDataset,\n",
    "    label_types = [\"detections\", \"segmentations\", \"keypoints\"],\n",
    "    data_path = f'/Users/john/datasets/mpii/images',\n",
    "    labels_path = f'/Users/john/datasets/mpii/mpii_human_pose_v1_u12_2/mpii_coco.json',\n",
    "    max_samples=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c61f25ab-cdb2-4ee5-9efd-b245f5d70ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "session.view = dataset.view()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
